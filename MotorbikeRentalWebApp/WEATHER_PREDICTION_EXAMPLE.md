# üå§Ô∏è V√ç D·ª§ D·ª∞ ƒêO√ÅN T·ª™ D·ªÆ LI·ªÜU TH·ªúI TI·∫æT H√îM NAY
## Weather Data Processing Example: From Today to 7-Day Forecast

---

## üéØ D·ªÆ LI·ªÜU TH·ªúI TI·∫æT H√îM NAY (D·ªÆ LI·ªÜU GI·∫¢)

### **D·ªØ li·ªáu th·ªùi ti·∫øt hi·ªán t·∫°i (2024-01-15):**

```python
# Current weather data - 2024-01-15 (H√¥m nay)
current_weather = {
    'date': '2024-01-15',
    'temperature': 28.5,      # ¬∞C
    'humidity': 65,           # %
    'wind_speed': 3.2,        # m/s
    'visibility': 10.5,       # km
    'dew_point': 22.1,        # ¬∞C
    'solar_radiation': 4.2,   # MJ/m¬≤
    'rainfall': 0,            # mm
    'season': 'Summer',       # M√πa h√®
    'holiday': 'No Holiday',  # Kh√¥ng ph·∫£i ng√†y l·ªÖ
    'hour': 14,               # 14:00 (2 gi·ªù chi·ªÅu)
    'day_of_week': 'Monday'   # Th·ª© 2
}
```

### **B·∫£ng d·ªØ li·ªáu th·ªùi ti·∫øt h√¥m nay:**

| Th·ªùi gian | Nhi·ªát ƒë·ªô | ƒê·ªô ·∫©m | Gi√≥ | T·∫ßm nh√¨n | ƒêi·ªÉm s∆∞∆°ng | B·ª©c x·∫° | M∆∞a | M√πa | L·ªÖ | Gi·ªù | Th·ª© |
|-----------|----------|-------|-----|----------|------------|--------|-----|-----|----|-----|-----|
| 14:00 | 28.5¬∞C | 65% | 3.2 m/s | 10.5 km | 22.1¬∞C | 4.2 MJ/m¬≤ | 0 mm | Summer | No Holiday | 14 | Monday |

---

## üîÑ B∆Ø·ªöC 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU L·ªäCH S·ª¨ (14 NG√ÄY TR∆Ø·ªöC)

### **D·ªØ li·ªáu l·ªãch s·ª≠ 14 ng√†y (2024-01-01 ƒë·∫øn 2024-01-14):**

```python
# Historical data - 14 ng√†y tr∆∞·ªõc h√¥m nay
historical_data = [
    # [Rented_Bikes, Hour, Temp, Humidity, Wind, Visibility, Dew_Point, Solar_Rad, Rainfall, Season, Holiday]
    [420, 14, 24.5, 68, 2.8, 9.5, 19.2, 3.2, 0, 'Summer', 'No Holiday'],    # 2024-01-01
    [435, 14, 25.2, 65, 3.1, 9.8, 20.1, 3.5, 0, 'Summer', 'No Holiday'],    # 2024-01-02
    [450, 14, 26.8, 62, 2.5, 10.2, 21.3, 3.8, 0, 'Summer', 'No Holiday'],   # 2024-01-03
    [465, 14, 27.1, 60, 2.9, 10.5, 22.0, 4.1, 0, 'Summer', 'No Holiday'],   # 2024-01-04
    [480, 14, 28.5, 58, 3.2, 10.8, 23.1, 4.3, 0, 'Summer', 'No Holiday'],   # 2024-01-05
    [520, 14, 29.2, 55, 2.7, 11.0, 24.2, 4.6, 0, 'Summer', 'No Holiday'],   # 2024-01-06
    [510, 14, 28.8, 57, 3.0, 10.7, 23.8, 4.4, 0, 'Summer', 'No Holiday'],   # 2024-01-07
    [445, 14, 26.3, 64, 3.4, 9.9, 20.8, 3.6, 0, 'Summer', 'No Holiday'],    # 2024-01-08
    [460, 14, 27.0, 61, 2.8, 10.1, 21.5, 3.9, 0, 'Summer', 'No Holiday'],   # 2024-01-09
    [475, 14, 28.1, 59, 3.1, 10.4, 22.3, 4.0, 0, 'Summer', 'No Holiday'],   # 2024-01-10
    [490, 14, 29.0, 56, 2.6, 10.6, 23.5, 4.2, 0, 'Summer', 'No Holiday'],   # 2024-01-11
    [505, 14, 30.2, 54, 2.9, 10.9, 24.8, 4.5, 0, 'Summer', 'No Holiday'],   # 2024-01-12
    [535, 14, 31.5, 52, 2.4, 11.2, 25.9, 4.8, 0, 'Summer', 'No Holiday'],   # 2024-01-13
    [525, 14, 30.8, 53, 2.7, 11.0, 25.2, 4.6, 0, 'Summer', 'No Holiday']    # 2024-01-14
]
```

---

## üîÑ B∆Ø·ªöC 2: K·∫æT H·ª¢P D·ªÆ LI·ªÜU HI·ªÜN T·∫†I V√ÄO L·ªäCH S·ª¨

### **D·ªØ li·ªáu sau khi th√™m th·ªùi ti·∫øt h√¥m nay:**

```python
# Combined data - 15 ng√†y (14 l·ªãch s·ª≠ + 1 hi·ªán t·∫°i)
combined_data = [
    # 14 ng√†y l·ªãch s·ª≠
    [420, 14, 24.5, 68, 2.8, 9.5, 19.2, 3.2, 0, 'Summer', 'No Holiday'],    # 2024-01-01
    [435, 14, 25.2, 65, 3.1, 9.8, 20.1, 3.5, 0, 'Summer', 'No Holiday'],    # 2024-01-02
    [450, 14, 26.8, 62, 2.5, 10.2, 21.3, 3.8, 0, 'Summer', 'No Holiday'],   # 2024-01-03
    [465, 14, 27.1, 60, 2.9, 10.5, 22.0, 4.1, 0, 'Summer', 'No Holiday'],   # 2024-01-04
    [480, 14, 28.5, 58, 3.2, 10.8, 23.1, 4.3, 0, 'Summer', 'No Holiday'],   # 2024-01-05
    [520, 14, 29.2, 55, 2.7, 11.0, 24.2, 4.6, 0, 'Summer', 'No Holiday'],   # 2024-01-06
    [510, 14, 28.8, 57, 3.0, 10.7, 23.8, 4.4, 0, 'Summer', 'No Holiday'],   # 2024-01-07
    [445, 14, 26.3, 64, 3.4, 9.9, 20.8, 3.6, 0, 'Summer', 'No Holiday'],    # 2024-01-08
    [460, 14, 27.0, 61, 2.8, 10.1, 21.5, 3.9, 0, 'Summer', 'No Holiday'],   # 2024-01-09
    [475, 14, 28.1, 59, 3.1, 10.4, 22.3, 4.0, 0, 'Summer', 'No Holiday'],   # 2024-01-10
    [490, 14, 29.0, 56, 2.6, 10.6, 23.5, 4.2, 0, 'Summer', 'No Holiday'],   # 2024-01-11
    [505, 14, 30.2, 54, 2.9, 10.9, 24.8, 4.5, 0, 'Summer', 'No Holiday'],   # 2024-01-12
    [535, 14, 31.5, 52, 2.4, 11.2, 25.9, 4.8, 0, 'Summer', 'No Holiday'],   # 2024-01-13
    [525, 14, 30.8, 53, 2.7, 11.0, 25.2, 4.6, 0, 'Summer', 'No Holiday'],   # 2024-01-14
    # H√¥m nay (ch∆∞a c√≥ s·ªë xe thu√™)
    [0, 14, 28.5, 65, 3.2, 10.5, 22.1, 4.2, 0, 'Summer', 'No Holiday']      # 2024-01-15 (H√¥m nay)
]
```

---

## üîÑ B∆Ø·ªöC 3: M√É H√ìA D·ªÆ LI·ªÜU (ENCODING)

### **T√°ch ri√™ng Numerical v√† Categorical:**

```python
# Numerical features (c·∫ßn scale)
numerical_features = [
    [420, 14, 24.5, 68, 2.8, 9.5, 19.2, 3.2, 0],    # Ng√†y 1
    [435, 14, 25.2, 65, 3.1, 9.8, 20.1, 3.5, 0],    # Ng√†y 2
    [450, 14, 26.8, 62, 2.5, 10.2, 21.3, 3.8, 0],   # Ng√†y 3
    [465, 14, 27.1, 60, 2.9, 10.5, 22.0, 4.1, 0],   # Ng√†y 4
    [480, 14, 28.5, 58, 3.2, 10.8, 23.1, 4.3, 0],   # Ng√†y 5
    [520, 14, 29.2, 55, 2.7, 11.0, 24.2, 4.6, 0],   # Ng√†y 6
    [510, 14, 28.8, 57, 3.0, 10.7, 23.8, 4.4, 0],   # Ng√†y 7
    [445, 14, 26.3, 64, 3.4, 9.9, 20.8, 3.6, 0],    # Ng√†y 8
    [460, 14, 27.0, 61, 2.8, 10.1, 21.5, 3.9, 0],   # Ng√†y 9
    [475, 14, 28.1, 59, 3.1, 10.4, 22.3, 4.0, 0],   # Ng√†y 10
    [490, 14, 29.0, 56, 2.6, 10.6, 23.5, 4.2, 0],   # Ng√†y 11
    [505, 14, 30.2, 54, 2.9, 10.9, 24.8, 4.5, 0],   # Ng√†y 12
    [535, 14, 31.5, 52, 2.4, 11.2, 25.9, 4.8, 0],   # Ng√†y 13
    [525, 14, 30.8, 53, 2.7, 11.0, 25.2, 4.6, 0],   # Ng√†y 14
    [0, 14, 28.5, 65, 3.2, 10.5, 22.1, 4.2, 0]      # Ng√†y 15 (H√¥m nay)
]

# Categorical features (c·∫ßn encoding)
categorical_features = [
    ['Summer', 'No Holiday'],    # Ng√†y 1
    ['Summer', 'No Holiday'],    # Ng√†y 2
    ['Summer', 'No Holiday'],    # Ng√†y 3
    ['Summer', 'No Holiday'],    # Ng√†y 4
    ['Summer', 'No Holiday'],    # Ng√†y 5
    ['Summer', 'No Holiday'],    # Ng√†y 6
    ['Summer', 'No Holiday'],    # Ng√†y 7
    ['Summer', 'No Holiday'],    # Ng√†y 8
    ['Summer', 'No Holiday'],    # Ng√†y 9
    ['Summer', 'No Holiday'],    # Ng√†y 10
    ['Summer', 'No Holiday'],    # Ng√†y 11
    ['Summer', 'No Holiday'],    # Ng√†y 12
    ['Summer', 'No Holiday'],    # Ng√†y 13
    ['Summer', 'No Holiday'],    # Ng√†y 14
    ['Summer', 'No Holiday']     # Ng√†y 15 (H√¥m nay)
]
```

One-Hot Encoding cho Categorical Features**

```python
# Seasons encoding
# Spring -> [1, 0, 0, 0] 
# Summer -> [0, 1, 0, 0]
# Autumn -> [0, 0, 1, 0]
# Winter -> [0, 0, 0, 1]
Spring ‚Üí [1, 0, 0, 0] (s·ªë 1 ·ªü v·ªã tr√≠ ƒë·∫ßu)
Summer ‚Üí [0, 1, 0, 0] (s·ªë 1 ·ªü v·ªã tr√≠ th·ª© 2)
Autumn ‚Üí [0, 0, 1, 0] (s·ªë 1 ·ªü v·ªã tr√≠ th·ª© 3)
Winter ‚Üí [0, 0, 0, 1] (s·ªë 1 ·ªü v·ªã tr√≠ cu·ªëi)

# Holiday encoding
# No Holiday -> [1, 0]
# Holiday -> [0, 1]

No Holiday ‚Üí [1, 0] (s·ªë 1 ·ªü v·ªã tr√≠ ƒë·∫ßu)
Holiday ‚Üí [0, 1] (s·ªë 1 ·ªü v·ªã tr√≠ th·ª© 2)

### **Sau One-Hot Encoding:**

```python
# Seasons encoding: Summer -> [0, 1, 0, 0]
# Holiday encoding: No Holiday -> [1, 0]

# Sau One-Hot Encoding:
encoded_categorical = [
    [0, 1, 0, 0, 1, 0],    # Ng√†y 1: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 2: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 3: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 4: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 5: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 6: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 7: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 8: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 9: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 10: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 11: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 12: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 13: Summer, No Holiday
    [0, 1, 0, 0, 1, 0],    # Ng√†y 14: Summer, No Holiday
    [0, 1, 0, 0, 1, 0]     # Ng√†y 15: Summer, No Holiday
]
```

### **D·ªØ li·ªáu sau encoding:**

```python
# Encoded data - 15 ng√†y sau encoding
encoded_data = [
    # [Rented_Bikes, Hour, Temp, Humidity, Wind, Visibility, Dew_Point, Solar_Rad, Rainfall, Season_Spring, Season_Summer, Season_Autumn, Season_Winter, Holiday_No, Holiday_Yes]
    [420, 14, 24.5, 68, 2.8, 9.5, 19.2, 3.2, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-01
    [435, 14, 25.2, 65, 3.1, 9.8, 20.1, 3.5, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-02
    [450, 14, 26.8, 62, 2.5, 10.2, 21.3, 3.8, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-03
    [465, 14, 27.1, 60, 2.9, 10.5, 22.0, 4.1, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-04
    [480, 14, 28.5, 58, 3.2, 10.8, 23.1, 4.3, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-05
    [520, 14, 29.2, 55, 2.7, 11.0, 24.2, 4.6, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-06
    [510, 14, 28.8, 57, 3.0, 10.7, 23.8, 4.4, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-07
    [445, 14, 26.3, 64, 3.4, 9.9, 20.8, 3.6, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-08
    [460, 14, 27.0, 61, 2.8, 10.1, 21.5, 3.9, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-09
    [475, 14, 28.1, 59, 3.1, 10.4, 22.3, 4.0, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-10
    [490, 14, 29.0, 56, 2.6, 10.6, 23.5, 4.2, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-11
    [505, 14, 30.2, 54, 2.9, 10.9, 24.8, 4.5, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-12
    [535, 14, 31.5, 52, 2.4, 11.2, 25.9, 4.8, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-13
    [525, 14, 30.8, 53, 2.7, 11.0, 25.2, 4.6, 0, 0, 1, 0, 0, 1, 0],   # 2024-01-14
    [0, 14, 28.5, 65, 3.2, 10.5, 22.1, 4.2, 0, 0, 1, 0, 0, 1, 0]      # 2024-01-15 (H√¥m nay)
]
```

---

## üîÑ B∆Ø·ªöC 4: SCALING D·ªÆ LI·ªÜU

### **MinMaxScaler cho Numerical Features:**

```python
# MinMaxScaler formula: (x - min) / (max - min)

# T√≠nh min/max t·ª´ d·ªØ li·ªáu l·ªãch s·ª≠ (14 ng√†y ƒë·∫ßu):
min_values = [420, 14, 24.5, 52, 2.4, 9.5, 19.2, 3.2, 0]  # Min c·ªßa m·ªói feature
max_values = [535, 14, 31.5, 68, 3.4, 11.2, 25.9, 4.8, 0]  # Max c·ªßa m·ªói feature

# Scaling cho ng√†y h√¥m nay (2024-01-15):
# [Rented_Bikes, Hour, Temp, Humidity, Wind, Visibility, Dew_Point, Solar_Rad, Rainfall]
original = [0, 14, 28.5, 65, 3.2, 10.5, 22.1, 4.2, 0]

# T√≠nh scaled values:
scaled_values = [
    (0 - 420) / (535 - 420) = -3.65,      # Rented_Bikes (s·∫Ω ƒë∆∞·ª£c thay th·∫ø)
    (14 - 14) / (14 - 14) = 0,            # Hour (c·ªë ƒë·ªãnh)
    (28.5 - 24.5) / (31.5 - 24.5) = 0.57, # Temperature
    (65 - 52) / (68 - 52) = 0.81,         # Humidity
    (3.2 - 2.4) / (3.4 - 2.4) = 0.80,     # Wind_Speed
    (10.5 - 9.5) / (11.2 - 9.5) = 0.59,   # Visibility
    (22.1 - 19.2) / (25.9 - 19.2) = 0.43, # Dew_Point
    (4.2 - 3.2) / (4.8 - 3.2) = 0.63,     # Solar_Radiation
    (0 - 0) / (0 - 0) = 0                 # Rainfall (c·ªë ƒë·ªãnh)
]
```

### **D·ªØ li·ªáu sau scaling:**

```python
# Scaled data - 15 ng√†y sau scaling
scaled_data = [
    # 14 ng√†y l·ªãch s·ª≠ (ƒë√£ ƒë∆∞·ª£c scale)
    [0.00, 0, 0.00, 1.00, 0.40, 0.00, 0.00, 0.00, 0],    # 2024-01-01
    [0.13, 0, 0.10, 0.81, 0.70, 0.18, 0.13, 0.19, 0],    # 2024-01-02
    [0.26, 0, 0.33, 0.59, 0.10, 0.41, 0.31, 0.38, 0],    # 2024-01-03
    [0.39, 0, 0.36, 0.50, 0.50, 0.59, 0.41, 0.56, 0],    # 2024-01-04
    [0.52, 0, 0.57, 0.38, 0.80, 0.76, 0.58, 0.69, 0],    # 2024-01-05
    [0.87, 0, 0.67, 0.19, 0.30, 0.88, 0.75, 0.88, 0],    # 2024-01-06
    [0.78, 0, 0.61, 0.31, 0.60, 0.71, 0.69, 0.75, 0],    # 2024-01-07
    [0.22, 0, 0.26, 0.75, 1.00, 0.24, 0.24, 0.25, 0],    # 2024-01-08
    [0.35, 0, 0.36, 0.56, 0.40, 0.35, 0.34, 0.44, 0],    # 2024-01-09
    [0.48, 0, 0.51, 0.44, 0.70, 0.53, 0.46, 0.50, 0],    # 2024-01-10
    [0.61, 0, 0.64, 0.25, 0.20, 0.65, 0.64, 0.63, 0],    # 2024-01-11
    [0.74, 0, 0.81, 0.13, 0.50, 0.82, 0.84, 0.81, 0],    # 2024-01-12
    [1.00, 0, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00, 0],    # 2024-01-13
    [0.91, 0, 0.90, 0.06, 0.30, 0.88, 0.90, 0.88, 0],    # 2024-01-14
    # H√¥m nay (ƒë√£ scale)
    [-3.65, 0, 0.57, 0.81, 0.80, 0.59, 0.43, 0.63, 0]   # 2024-01-15 (H√¥m nay)
]
```

---

## üîÑ B∆Ø·ªöC 5: CHU·∫®N B·ªä INPUT CHO LSTM

### **Input shape cho LSTM:**

```python
# L·∫•y 14 ng√†y cu·ªëi c√πng (kh√¥ng bao g·ªìm h√¥m nay) l√†m input
lstm_input_data = [
    [0.13, 0, 0.10, 0.81, 0.70, 0.18, 0.13, 0.19, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-02
    [0.26, 0, 0.33, 0.59, 0.10, 0.41, 0.31, 0.38, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-03
    [0.39, 0, 0.36, 0.50, 0.50, 0.59, 0.41, 0.56, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-04
    [0.52, 0, 0.57, 0.38, 0.80, 0.76, 0.58, 0.69, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-05
    [0.87, 0, 0.67, 0.19, 0.30, 0.88, 0.75, 0.88, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-06
    [0.78, 0, 0.61, 0.31, 0.60, 0.71, 0.69, 0.75, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-07
    [0.22, 0, 0.26, 0.75, 1.00, 0.24, 0.24, 0.25, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-08
    [0.35, 0, 0.36, 0.56, 0.40, 0.35, 0.34, 0.44, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-09
    [0.48, 0, 0.51, 0.44, 0.70, 0.53, 0.46, 0.50, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-10
    [0.61, 0, 0.64, 0.25, 0.20, 0.65, 0.64, 0.63, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-11
    [0.74, 0, 0.81, 0.13, 0.50, 0.82, 0.84, 0.81, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-12
    [1.00, 0, 1.00, 0.00, 0.00, 1.00, 1.00, 1.00, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-13
    [0.91, 0, 0.90, 0.06, 0.30, 0.88, 0.90, 0.88, 0, 0, 1, 0, 0, 1, 0],    # 2024-01-14
    [-3.65, 0, 0.57, 0.81, 0.80, 0.59, 0.43, 0.63, 0, 0, 1, 0, 0, 1, 0]   # 2024-01-15 (H√¥m nay)
]

# Reshape th√†nh (1, 14, 15) cho LSTM
lstm_input = np.array(lstm_input_data).reshape(1, 14, 15)

LSTM y√™u c·∫ßu input format ƒë·∫∑c bi·ªát:
LSTM c·∫ßn d·ªØ li·ªáu 3D: (batch_size, timesteps, features)
Kh√¥ng th·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu 2D th√¥ng th∆∞·ªùng

B∆∞·ªõc 1: D·ªØ li·ªáu g·ªëc (2D)
lstm_input_data = [
    [0.13, 0, 0.10, 0.81, 0.70, 0.18, 0.13, 0.19, 0, 0, 1, 0, 0, 1, 0],    # Ng√†y 1
    [0.26, 0, 0.33, 0.59, 0.10, 0.41, 0.31, 0.38, 0, 0, 1, 0, 0, 1, 0],    # Ng√†y 2
    [0.39, 0, 0.36, 0.50, 0.50, 0.59, 0.41, 0.56, 0, 0, 1, 0, 0, 1, 0],    # Ng√†y 3
    # ... 11 ng√†y n·ªØa ...
    [-3.65, 0, 0.57, 0.81, 0.80, 0.59, 0.43, 0.63, 0, 0, 1, 0, 0, 1, 0]   # Ng√†y 14
]

Shape: (14, 15) - 14 h√†ng, 15 c·ªôt

B∆∞·ªõc 2: Reshape th√†nh 3D
Shape: (1, 14, 15) - 1 batch, 14 timesteps, 15 features

Chi·ªÅu 1: Batch Size = 1
# 1 = Ch·ªâ c√≥ 1 m·∫´u d·ªØ li·ªáu
# N·∫øu c√≥ nhi·ªÅu m·∫´u: (10, 14, 15) = 10 m·∫´u kh√°c nhau

Chi·ªÅu 2: Timesteps = 14
# 14 = 14 ng√†y l·ªãch s·ª≠
# M·ªói ng√†y = 1 timestep
# LSTM s·∫Ω h·ªçc pattern t·ª´ 14 ng√†y n√†y

Chi·ªÅu 3: Features = 15
# 15 = 15 features cho m·ªói ng√†y
# [Rented_Bikes, Hour, Temp, Humidity, Wind, Visibility, Dew_Point, Solar_Rad, Rainfall, Season_Spring, Season_Summer, Season_Autumn, Season_Winter, Holiday_No, Holiday_Yes]

Shape: (1, 14, 15)

Batch 1:
‚îú‚îÄ‚îÄ Timestep 1 (Ng√†y 1): [0.13, 0, 0.10, 0.81, 0.70, 0.18, 0.13, 0.19, 0, 0, 1, 0, 0, 1, 0]
‚îú‚îÄ‚îÄ Timestep 2 (Ng√†y 2): [0.26, 0, 0.33, 0.59, 0.10, 0.41, 0.31, 0.38, 0, 0, 1, 0, 0, 1, 0]
‚îú‚îÄ‚îÄ Timestep 3 (Ng√†y 3): [0.39, 0, 0.36, 0.50, 0.50, 0.59, 0.41, 0.56, 0, 0, 1, 0, 0, 1, 0]
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ Timestep 14 (Ng√†y 14): [-3.65, 0, 0.57, 0.81, 0.80, 0.59, 0.43, 0.63, 0, 0, 1, 0, 0, 1, 0]

üß† T·∫°i sao LSTM c·∫ßn format n√†y?
1. Sequential Learning
# LSTM h·ªçc theo th·ª© t·ª± th·ªùi gian:
# Ng√†y 1 ‚Üí Ng√†y 2 ‚Üí Ng√†y 3 ‚Üí ... ‚Üí Ng√†y 14
# M·ªói timestep = 1 ng√†y
2. Memory Mechanism
# LSTM nh·ªõ th√¥ng tin t·ª´ c√°c ng√†y tr∆∞·ªõc:
# Ng√†y 14 c√≥ th·ªÉ ·∫£nh h∆∞·ªüng b·ªüi Ng√†y 1, 2, 3, ..., 13
3. Feature Processing
# M·ªói timestep c√≥ 15 features:
# - 9 numerical features (ƒë√£ scale)
# - 6 categorical features (ƒë√£ encode)

```

---

## üîÑ B∆Ø·ªöC 6: LSTM PREDICTION

### **LSTM Model Processing:**

```python
# LSTM Model Architecture:
# Input: (1, 14, 15) -> LSTM(50) -> Dropout(0.2) -> LSTM(30) -> Dropout(0.2) -> Dense(1)

# Forward pass qua LSTM:
# Layer 1: LSTM(50 neurons)
lstm1_output = lstm_layer1(lstm_input)  # Shape: (1, 14, 50)

# Layer 2: LSTM(30 neurons)
lstm2_output = lstm_layer2(lstm1_output)  # Shape: (1, 30)

# Dropout layers
dropout1_output = dropout_layer1(lstm2_output)  # Shape: (1, 30)
dropout2_output = dropout_layer2(dropout1_output)  # Shape: (1, 30)

# Dense layer
dense_output = dense_layer(dropout2_output)  # Shape: (1, 1)

# Predicted value (scaled)
predicted_scaled = 0.73  # Gi√° tr·ªã d·ª± ƒëo√°n ƒë√£ scale (0-1)
```

### **Inverse Scaling:**

```python
# Inverse MinMaxScaler: original = scaled * (max - min) + min
# Rented_Bikes: min=420, max=535

predicted_original = predicted_scaled * (535 - 420) + 420
predicted_original = 0.73 * 115 + 420
predicted_original = 83.95 + 420
predicted_original = 503.95 ‚âà 504 bikes
```

---

## üîÑ B∆Ø·ªöC 7: GENERATE 7-DAY FORECAST

### **Base Prediction v√† Day Variations:**

```python
# Base prediction cho h√¥m nay
base_prediction = 504 bikes

# Day variation factors (d·ª±a tr√™n pattern l·ªãch s·ª≠)
day_variations = {
    'Monday': 1.05,    # Th·ª© 2: tƒÉng 5%
    'Tuesday': 1.02,   # Th·ª© 3: tƒÉng 2%
    'Wednesday': 1.00, # Th·ª© 4: gi·ªØ nguy√™n
    'Thursday': 0.98,  # Th·ª© 5: gi·∫£m 2%
    'Friday': 1.03,    # Th·ª© 6: tƒÉng 3%
    'Saturday': 1.08,  # Th·ª© 7: tƒÉng 8%
    'Sunday': 1.06     # Ch·ªß nh·∫≠t: tƒÉng 6%
}

# Weather adjustment factors
weather_adjustments = {
    'temperature': 1.02,  # Nhi·ªát ƒë·ªô cao -> tƒÉng 2%
    'humidity': 0.98,     # ƒê·ªô ·∫©m cao -> gi·∫£m 2%
    'wind': 0.99,         # Gi√≥ m·∫°nh -> gi·∫£m 1%
    'visibility': 1.01    # T·∫ßm nh√¨n t·ªët -> tƒÉng 1%
}
```

### **7-Day Forecast Generation:**

```python
# Generate forecast cho 7 ng√†y ti·∫øp theo
forecast_days = [
    '2024-01-16', '2024-01-17', '2024-01-18', '2024-01-19',
    '2024-01-20', '2024-01-21', '2024-01-22'
]

forecast_results = []

for i, date in enumerate(forecast_days):
    # T√≠nh day variation
    day_of_week = ['Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'Monday'][i]
    day_factor = day_variations[day_of_week]
    
    # T√≠nh weather adjustment (gi·∫£ s·ª≠ th·ªùi ti·∫øt t∆∞∆°ng t·ª±)
    weather_factor = weather_adjustments['temperature'] * weather_adjustments['humidity'] * weather_adjustments['wind'] * weather_adjustments['visibility']
    weather_factor = 1.02 * 0.98 * 0.99 * 1.01 = 1.00
    
    # T√≠nh prediction cho ng√†y n√†y
    day_prediction = base_prediction * day_factor * weather_factor
    
    # Th√™m noise (¬±5%)
    noise = np.random.uniform(0.95, 1.05)
    final_prediction = int(day_prediction * noise)
    
    forecast_results.append({
        'date': date,
        'day_of_week': day_of_week,
        'predicted_bikes': final_prediction,
        'confidence': 0.85  # ƒê·ªô tin c·∫≠y
    })
```

---

## üìä K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN 7 NG√ÄY

### **Forecast Results:**

```python
# 7-day forecast results
forecast_output = [
    {
        'date': '2024-01-16',
        'day_of_week': 'Tuesday',
        'predicted_bikes': 514,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-17',
        'day_of_week': 'Wednesday',
        'predicted_bikes': 504,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-18',
        'day_of_week': 'Thursday',
        'predicted_bikes': 494,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-19',
        'day_of_week': 'Friday',
        'predicted_bikes': 519,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-20',
        'day_of_week': 'Saturday',
        'predicted_bikes': 544,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-21',
        'day_of_week': 'Sunday',
        'predicted_bikes': 534,
        'confidence': 0.85,
        'weather': 'Similar to today'
    },
    {
        'date': '2024-01-22',
        'day_of_week': 'Monday',
        'predicted_bikes': 529,
        'confidence': 0.85,
        'weather': 'Similar to today'
    }
]
```

### **B·∫£ng t√≥m t·∫Øt d·ª± ƒëo√°n:**

| Ng√†y | Th·ª© | D·ª± ƒëo√°n xe | ƒê·ªô tin c·∫≠y | Ghi ch√∫ |
|------|-----|------------|------------|---------|
| 2024-01-16 | Th·ª© 3 | 514 xe | 85% | TƒÉng nh·∫π so v·ªõi h√¥m nay |
| 2024-01-17 | Th·ª© 4 | 504 xe | 85% | T∆∞∆°ng ƒë∆∞∆°ng h√¥m nay |
| 2024-01-18 | Th·ª© 5 | 494 xe | 85% | Gi·∫£m nh·∫π |
| 2024-01-19 | Th·ª© 6 | 519 xe | 85% | TƒÉng do cu·ªëi tu·∫ßn |
| 2024-01-20 | Th·ª© 7 | 544 xe | 85% | Cao nh·∫•t trong tu·∫ßn |
| 2024-01-21 | Ch·ªß nh·∫≠t | 534 xe | 85% | Cao do cu·ªëi tu·∫ßn |
| 2024-01-22 | Th·ª© 2 | 529 xe | 85% | TƒÉng do ƒë·∫ßu tu·∫ßn |

---

## üéØ T√ìM T·∫ÆT QU√Å TR√åNH

### **T·ª´ d·ªØ li·ªáu th·ªùi ti·∫øt h√¥m nay ƒë·∫øn d·ª± ƒëo√°n 7 ng√†y:**

1. **Thu th·∫≠p d·ªØ li·ªáu:** Th·ªùi ti·∫øt h√¥m nay (28.5¬∞C, 65% ƒë·ªô ·∫©m, etc.)
2. **K·∫øt h·ª£p l·ªãch s·ª≠:** Th√™m v√†o 14 ng√†y d·ªØ li·ªáu l·ªãch s·ª≠
3. **M√£ h√≥a:** One-Hot Encoding cho Season v√† Holiday
4. **Scaling:** MinMaxScaler cho numerical features
5. **LSTM Input:** Chu·∫©n b·ªã (1, 14, 15) cho model
6. **Prediction:** LSTM d·ª± ƒëo√°n base prediction (504 xe)
7. **Forecast:** √Åp d·ª•ng day variations v√† weather adjustments
8. **Output:** 7 ng√†y d·ª± ƒëo√°n v·ªõi ƒë·ªô tin c·∫≠y 85%

**K·∫øt qu·∫£:** D·ª± ƒëo√°n t·ª´ 494-544 xe trong 7 ng√†y t·ªõi, v·ªõi pattern tƒÉng v√†o cu·ªëi tu·∫ßn v√† gi·∫£m v√†o gi·ªØa tu·∫ßn.

T√¥i s·∫Ω gi·∫£i th√≠ch b·∫±ng l·ªùi v√† minh h·ªça chi ti·∫øt ph·∫ßn LSTM Prediction v√† 7-Day Forecast Generation:
üß† GI·∫¢I TH√çCH LSTM PREDICTION
üéØ Ki·∫øn tr√∫c LSTM Model
C·∫•u tr√∫c m·∫°ng neural:
Input: 15 features t·ª´ 14 ng√†y l·ªãch s·ª≠
LSTM Layer 1: 50 neurons (h·ªçc patterns ph·ª©c t·∫°p)
Dropout 1: Lo·∫°i b·ªè 20% connections (tr√°nh overfitting)
LSTM Layer 2: 30 neurons (tinh ch·ªânh patterns)
Dropout 2: Lo·∫°i b·ªè 20% connections
Dense Layer: 1 neuron (cho ra k·∫øt qu·∫£ cu·ªëi c√πng)
üéØ 4. DROPOUT l√† g√¨?
Dropout l√† g√¨?
ƒê·ªãnh nghƒ©a: K·ªπ thu·∫≠t "t·∫Øt" ng·∫´u nhi√™n m·ªôt s·ªë neurons
M·ª•c ƒë√≠ch: NgƒÉn ch·∫∑n overfitting
C√°ch ho·∫°t ƒë·ªông: M·ªói l·∫ßn training, t·∫Øt 20% neurons
V√≠ d·ª• minh h·ªça:
T·∫°i sao Dropout hi·ªáu qu·∫£?
Bu·ªôc model: Kh√¥ng ph·ª• thu·ªôc v√†o 1 s·ªë neurons c·ª• th·ªÉ
TƒÉng t√≠nh robust: Model h·ªçc patterns t·ªïng qu√°t h∆°n
Gi·∫£m overfitting: Kh√¥ng th·ªÉ "thu·ªôc l√≤ng" d·ªØ li·ªáu
LSTM Layer c√≥ 50 neurons:
- L·∫ßn training 1: T·∫Øt neurons 1, 5, 12, 23, 45 (10 neurons = 20%)
- L·∫ßn training 2: T·∫Øt neurons 3, 8, 15, 28, 41 (10 neurons kh√°c)
- L·∫ßn training 3: T·∫Øt neurons 2, 7, 19, 31, 44 (10 neurons kh√°c)
üéØ T√ìM T·∫ÆT
50 Neurons: 50 ƒë∆°n v·ªã x·ª≠ l√Ω song song, h·ªçc 50 patterns kh√°c nhau
20% Connections: Lo·∫°i b·ªè 20% k·∫øt n·ªëi ƒë·ªÉ tr√°nh overfitting
Overfitting: Model h·ªçc "thu·ªôc l√≤ng" thay v√¨ hi·ªÉu patterns th·ª±c s·ª±
Dropout: K·ªπ thu·∫≠t ngƒÉn ch·∫∑n overfitting b·∫±ng c√°ch t·∫Øt ng·∫´u nhi√™n neurons
Layers: C√°c t·∫ßng x·ª≠ l√Ω kh√°c nhau, t·ª´ c∆° b·∫£n ƒë·∫øn ph·ª©c t·∫°p
Features: Th√¥ng tin ƒë·∫ßu v√†o (nhi·ªát ƒë·ªô, ƒë·ªô ·∫©m, etc.)
M·ª•c ti√™u cu·ªëi c√πng: T·∫°o ra model c√≥ th·ªÉ h·ªçc patterns th·ª±c s·ª± v√† d·ª± ƒëo√°n ch√≠nh x√°c cho d·ªØ li·ªáu m·ªõi.
================================
ÔøΩÔøΩ Qu√° tr√¨nh x·ª≠ l√Ω t·ª´ng layer
Layer 1 - LSTM(50):
Input: 14 ng√†y √ó 15 features = 210 gi√° tr·ªã
X·ª≠ l√Ω: H·ªçc patterns ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu l·ªãch s·ª≠
Output: 14 ng√†y √ó 50 features = 700 gi√° tr·ªã
√ù nghƒ©a: M·ªói ng√†y ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng 50 ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p
50 features n√†y ƒë∆∞·ª£c t·∫°o qua c√°c l·∫ßn h·ªçc
ÔøΩÔøΩ MINH H·ªåA QU√Å TR√åNH H·ªåC PATTERNS C√ì √ù NGHƒ®A
# T·∫•t c·∫£ patterns: Ng·∫´u nhi√™n
# D·ª± ƒëo√°n: Sai nhi·ªÅu
# Loss: Cao
v√≠ d·ª• nhi·ªát ƒë·ªô cao --> d·ª± ƒëo√°n 420 xe --> xe tƒÉng
           th·ª±c t·∫ø --> 300 xe --> xe gi·∫£m sai
# Pattern 1: B·∫Øt ƒë·∫ßu h·ªçc "nhi·ªát ƒë·ªô quan tr·ªçng"
# Pattern 2: B·∫Øt ƒë·∫ßu h·ªçc "ƒë·ªô ·∫©m quan tr·ªçng"
# D·ª± ƒëo√°n: B·ªõt sai
# Loss: Gi·∫£m
# Pattern 1: "Nhi·ªát ƒë·ªô cao ‚Üí tƒÉng xe" (r√µ r√†ng)
# Pattern 2: "ƒê·ªô ·∫©m cao ‚Üí gi·∫£m xe" (r√µ r√†ng)
# Pattern 3: "T∆∞∆°ng t√°c nhi·ªát ƒë·ªô + ƒë·ªô ·∫©m" (r√µ r√†ng)
# D·ª± ƒëo√°n: Ch√≠nh x√°c
# Loss: Th·∫•p
üéØ C√ÅCH ƒê√ÅNH GI√Å PATTERN C√ì √ù NGHƒ®A HAY KH√îNG
1. ƒê√ÅNH GI√Å QUA LOSS FUNCTION
# Pattern 1: 0.8 √ó Temperature + 0.1 √ó Humidity
# Khi s·ª≠ d·ª•ng pattern n√†y:
# Loss = 10 (d·ª± ƒëo√°n g·∫ßn th·ª±c t·∫ø)
# ‚Üí Pattern c√≥ √Ω nghƒ©a v√¨ gi√∫p d·ª± ƒëo√°n ƒë√∫ng
iiiiii
# Pattern 2: 0.1 √ó Temperature + 0.9 √ó Rainfall + 0.2 √ó (Hour √ó Dew_Point)
# Khi s·ª≠ d·ª•ng pattern n√†y:
# Loss = 1000 (d·ª± ƒëo√°n sai nhi·ªÅu)
# ‚Üí Pattern kh√¥ng c√≥ √Ω nghƒ©a v√¨ kh√¥ng gi√∫p d·ª± ƒëo√°n
2. ƒê√ÅNH GI√Å QUA CORRELATION (T∆Ø∆†NG QUAN)
# Pattern: Temperature vs Bike_Count
# Correlation = 0.8 (t∆∞∆°ng quan cao)
# ‚Üí Nhi·ªát ƒë·ªô c√≥ ·∫£nh h∆∞·ªüng m·∫°nh ƒë·∫øn s·ªë xe thu√™
# ‚Üí Pattern c√≥ √Ω nghƒ©a
# Pattern: Rainfall vs Bike_Count  
# Correlation = 0.1 (t∆∞∆°ng quan th·∫•p)
# ‚Üí M∆∞a √≠t ·∫£nh h∆∞·ªüng ƒë·∫øn s·ªë xe thu√™
# ‚Üí Pattern √≠t √Ω nghƒ©a
Layer 2 - LSTM(30):
Input: 14 ng√†y √ó 50 features t·ª´ layer 1
X·ª≠ l√Ω: Tinh ch·ªânh v√† t·ªïng h·ª£p patterns
Output: 30 features cu·ªëi c√πng
√ù nghƒ©a: T√≥m t·∫Øt to√†n b·ªô th√¥ng tin 14 ng√†y th√†nh 30 ƒë·∫∑c tr∆∞ng quan tr·ªçng
‚ÄúC√≥ ph·∫£i Layer 1 ƒë√£ tinh ch·ªânh 1 l·∫ßn ƒë·ªÉ l·∫•y 50 pattern c√≥ √Ω nghƒ©a r·ªìi kh√¥ng?‚Äù:
Layer 1 h·ªçc ra 50 ƒë·∫∑c tr∆∞ng (v√¨ hidden_size=50) ‚Äî ƒë√¢y kh√¥ng ph·∫£i ‚Äúch·ªçn l·ªçc‚Äù t·ª´ t·∫≠p l·ªõn h∆°n, m√† l√† 50 k√™nh bi·ªÉu di·ªÖn do b·∫°n c·∫•u h√¨nh.
Kh√¥ng ph·∫£i t·∫•t c·∫£ 50 ƒë·ªÅu ‚Äúho√†n h·∫£o‚Äù; trong qu√° tr√¨nh hu·∫•n luy·ªán end-to-end, nhi·ªÅu unit tr·ªü n√™n h·ªØu √≠ch, v√†i unit c√≥ th·ªÉ d∆∞ th·ª´a/·ªìn.
Layer 2 ƒë√≥ng vai tr√≤ ‚Äúbottleneck‚Äù (t·ª´ 50 xu·ªëng 30), ti·∫øp t·ª•c l·ªçc/gh√©p c√°c ƒë·∫∑c tr∆∞ng Layer 1 th√†nh 30 ƒë·∫∑c tr∆∞ng g·ªçn h∆°n, c√≥ t√≠nh kh√°i qu√°t cao h∆°n.
=====================
Dropout Layers: tr√°nh h·ªçc thu·ªôc l√≤ng
M·ª•c ƒë√≠ch: NgƒÉn ch·∫∑n overfitting 
C√°ch ho·∫°t ƒë·ªông: T·∫°m th·ªùi "t·∫Øt" 20% connections
K·∫øt qu·∫£: Model h·ªçc robust h∆°n, kh√¥ng ph·ª• thu·ªôc qu√° nhi·ªÅu v√†o m·ªôt s·ªë features
# Model h·ªçc "thu·ªôc l√≤ng" d·ªØ li·ªáu training
# Neuron 1: "T√¥i nh·ªõ ch√≠nh x√°c ng√†y 1 c√≥ 420 xe"
# Neuron 2: "T√¥i nh·ªõ ch√≠nh x√°c ng√†y 2 c√≥ 435 xe"
# Neuron 3: "T√¥i nh·ªõ ch√≠nh x√°c ng√†y 3 c√≥ 450 xe"
# ...

# K·∫øt qu·∫£: R·∫•t t·ªët tr√™n d·ªØ li·ªáu c≈©, r·∫•t t·ªá tr√™n d·ªØ li·ªáu m·ªõi
# Epoch 1: Neuron 1 b·ªã t·∫Øt
# Model: "T√¥i ph·∫£i h·ªçc pattern m√† kh√¥ng c√≥ Neuron 1"
# ‚Üí T√¨m pattern kh√°c ƒë·ªÉ d·ª± ƒëo√°n

# Epoch 2: Neuron 2 b·ªã t·∫Øt  
# Model: "T√¥i ph·∫£i h·ªçc pattern m√† kh√¥ng c√≥ Neuron 2"
# ‚Üí T√¨m pattern kh√°c ƒë·ªÉ d·ª± ƒëo√°n

# Epoch 3: Neuron 3 b·ªã t·∫Øt
# Model: "T√¥i ph·∫£i h·ªçc pattern m√† kh√¥ng c√≥ Neuron 3"
# ‚Üí T√¨m pattern kh√°c ƒë·ªÉ d·ª± ƒëo√°n

# K·∫øt qu·∫£: Model h·ªçc patterns t·ªïng qu√°t, kh√¥ng ph·ª• thu·ªôc v√†o 1 neuron c·ª• th·ªÉ
Dense Layer:
Input: 30 features t·ª´ LSTM
X·ª≠ l√Ω: T√≠nh to√°n tr·ªçng s·ªë v√† bias
# Input t·ª´ LSTM (30 features):
lstm_features = [0.8, 0.6, 0.9, 0.3, 0.7, 0.5, 0.4, 0.8, 0.2, 0.6, 0.9, 0.1, 0.5, 0.7, 0.3, 0.8, 0.4, 0.6, 0.2, 0.9, 0.5, 0.7, 0.1, 0.8, 0.3, 0.6, 0.4, 0.9, 0.2, 0.5]

# Weights (ƒë∆∞·ª£c h·ªçc trong qu√° tr√¨nh training):
weights = [0.1, 0.2, 0.15, 0.05, 0.12, 0.08, 0.06, 0.18, 0.03, 0.11, 0.16, 0.02, 0.09, 0.14, 0.04, 0.17, 0.07, 0.13, 0.01, 0.19, 0.1, 0.15, 0.02, 0.18, 0.05, 0.12, 0.08, 0.2, 0.03, 0.11]

# Bias:
bias = 0.05

# T√≠nh output:
output = 0.1*0.8 + 0.2*0.6 + 0.15*0.9 + 0.05*0.3 + 0.12*0.7 + 0.08*0.5 + 0.06*0.4 + 0.18*0.8 + 0.03*0.2 + 0.11*0.6 + 0.16*0.9 + 0.02*0.1 + 0.09*0.5 + 0.14*0.7 + 0.04*0.3 + 0.17*0.8 + 0.07*0.4 + 0.13*0.6 + 0.01*0.2 + 0.19*0.9 + 0.1*0.5 + 0.15*0.7 + 0.02*0.1 + 0.18*0.8 + 0.05*0.3 + 0.12*0.6 + 0.08*0.4 + 0.2*0.9 + 0.03*0.2 + 0.11*0.5 + 0.05

# Weight cao = Feature quan tr·ªçng
weights = [0.1, 0.2, 0.15, 0.05, 0.12, 0.08, 0.06, 0.18, 0.03, 0.11, 0.16, 0.02, 0.09, 0.14, 0.04, 0.17, 0.07, 0.13, 0.01, 0.19, 0.1, 0.15, 0.02, 0.18, 0.05, 0.12, 0.08, 0.2, 0.03, 0.11]

# Ph√¢n t√≠ch:
# Weight cao nh·∫•t: 0.2 (feature 28) ‚Üí Feature quan tr·ªçng nh·∫•t
# Weight th·∫•p nh·∫•t: 0.01 (feature 19) ‚Üí Feature √≠t quan tr·ªçng
# Weight trung b√¨nh: 0.1-0.15 ‚Üí Features quan tr·ªçng v·ª´a ph·∫£i

# Bias = 0.05
# √ù nghƒ©a: Ngay c·∫£ khi t·∫•t c·∫£ features = 0, output v·∫´n = 0.05
# ‚Üí ƒêi·ªÅu ch·ªânh baseline c·ªßa d·ª± ƒëo√°n

# K·∫øt qu·∫£:
output = 0.73  # Gi√° tr·ªã d·ª± ƒëo√°n ƒë√£ scale (0-1)
Output: 1 gi√° tr·ªã (s·ªë xe d·ª± ƒëo√°n ƒë√£ scale)
üìä K·∫øt qu·∫£ d·ª± ƒëo√°n
Gi√° tr·ªã d·ª± ƒëo√°n: 0.73 (ƒë√£ scale t·ª´ 0-1)
√ù nghƒ©a: Model d·ª± ƒëo√°n m·ª©c ƒë·ªô thu√™ xe ·ªü m·ª©c 73% so v·ªõi range l·ªãch s·ª≠
üîÑ Inverse Scaling
C√¥ng th·ª©c: Gi√° tr·ªã g·ªëc = Gi√° tr·ªã scale √ó (Max - Min) + Min
Gi√° tr·ªã scale: 0.73
Range l·ªãch s·ª≠: 420-535 xe
T√≠nh to√°n: 0.73 √ó (535-420) + 420 = 0.73 √ó 115 + 420 = 504 xe
K·∫øt qu·∫£: D·ª± ƒëo√°n 504 xe cho ng√†y h√¥m nay
ÔøΩÔøΩ GI·∫¢I TH√çCH 7-DAY FORECAST GENERATION
üéØ Nguy√™n l√Ω d·ª± ƒëo√°n
T·ª´ 1 ng√†y ‚Üí 7 ng√†y:
Base prediction: 504 xe (t·ª´ LSTM)
√Åp d·ª•ng patterns: Theo ng√†y trong tu·∫ßn
ƒêi·ªÅu ch·ªânh th·ªùi ti·∫øt: Theo ƒëi·ªÅu ki·ªán hi·ªán t·∫°i
Th√™m randomness: M√¥ ph·ªèng th·ª±c t·∫ø
üìä Day Variation Factors
Patterns theo ng√†y trong tu·∫ßn:
Th·ª© 2: +5% (ƒë·∫ßu tu·∫ßn, ng∆∞·ªùi ƒëi l√†m)
Th·ª© 3: +2% (·ªïn ƒë·ªãnh)
Th·ª© 4: 0% (gi·ªØ nguy√™n)
Th·ª© 5: -2% (cu·ªëi tu·∫ßn l√†m vi·ªác)
Th·ª© 6: +3% (cu·ªëi tu·∫ßn, ng∆∞·ªùi ƒëi ch∆°i)
Th·ª© 7: +8% (cu·ªëi tu·∫ßn, cao nh·∫•t)
Ch·ªß nh·∫≠t: +6% (cu·ªëi tu·∫ßn, nh∆∞ng √≠t h∆°n th·ª© 7)
üå§Ô∏è Weather Adjustment Factors
·∫¢nh h∆∞·ªüng th·ªùi ti·∫øt:
Nhi·ªát ƒë·ªô cao: +2% (th·ªùi ti·∫øt ƒë·∫πp, nhi·ªÅu ng∆∞·ªùi thu√™)
ƒê·ªô ·∫©m cao: -2% (kh√≥ ch·ªãu, √≠t ng∆∞·ªùi thu√™)
Gi√≥ m·∫°nh: -1% (kh√≥ ƒëi xe)
T·∫ßm nh√¨n t·ªët: +1% (an to√†n h∆°n)
üîÑ Qu√° tr√¨nh t√≠nh to√°n cho t·ª´ng ng√†y
V√≠ d·ª• cho ng√†y ƒë·∫ßu ti√™n (Th·ª© 3):
Base prediction: 504 xe
Day factor: 1.02 (+2% cho th·ª© 3)
Weather factor: 1.00 (th·ªùi ti·∫øt t∆∞∆°ng t·ª±)
T√≠nh to√°n: 504 √ó 1.02 √ó 1.00 = 514 xe
Th√™m noise: ¬±5% randomness
K·∫øt qu·∫£: 514 xe
ÔøΩÔøΩ K·∫øt qu·∫£ 7 ng√†y
Pattern d·ª± ƒëo√°n:
Th·ª© 3: 514 xe (tƒÉng nh·∫π)
Th·ª© 4: 504 xe (gi·ªØ nguy√™n)
Th·ª© 5: 494 xe (gi·∫£m nh·∫π)
Th·ª© 6: 519 xe (tƒÉng do cu·ªëi tu·∫ßn)
Th·ª© 7: 544 xe (cao nh·∫•t)
Ch·ªß nh·∫≠t: 534 xe (cao nh∆∞ng √≠t h∆°n th·ª© 7)
Th·ª© 2: 529 xe (tƒÉng do ƒë·∫ßu tu·∫ßn)
üéØ √ù nghƒ©a th·ª±c t·∫ø
Patterns ƒë∆∞·ª£c h·ªçc:
Cu·ªëi tu·∫ßn: Nhu c·∫ßu cao h∆°n (ng∆∞·ªùi ƒëi ch∆°i)
ƒê·∫ßu tu·∫ßn: Nhu c·∫ßu trung b√¨nh (ng∆∞·ªùi ƒëi l√†m)
Gi·ªØa tu·∫ßn: Nhu c·∫ßu th·∫•p nh·∫•t
Th·ªùi ti·∫øt: ·∫¢nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn quy·∫øt ƒë·ªãnh thu√™ xe
ƒê·ªô tin c·∫≠y: 85% - Model kh√° t·ª± tin v·ªÅ d·ª± ƒëo√°n n√†y
T√≥m l·∫°i: T·ª´ 1 d·ª± ƒëo√°n c∆° b·∫£n, model √°p d·ª•ng c√°c patterns ƒë√£ h·ªçc ƒë·ªÉ t·∫°o ra d·ª± ƒëo√°n 7 ng√†y v·ªõi ƒë·ªô ch√≠nh x√°c cao v√† ph·∫£n √°nh th·ª±c t·∫ø cu·ªôc s·ªëng.
